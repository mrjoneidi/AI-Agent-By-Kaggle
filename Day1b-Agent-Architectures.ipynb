{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:13:54.114002Z","iopub.execute_input":"2025-12-01T10:13:54.114339Z","iopub.status.idle":"2025-12-01T10:13:54.160824Z","shell.execute_reply.started":"2025-12-01T10:13:54.114316Z","shell.execute_reply":"2025-12-01T10:13:54.159958Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:13:59.229942Z","iopub.execute_input":"2025-12-01T10:13:59.230270Z","iopub.status.idle":"2025-12-01T10:14:52.293513Z","shell.execute_reply.started":"2025-12-01T10:13:59.230245Z","shell.execute_reply":"2025-12-01T10:14:52.292511Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:14:52.294869Z","iopub.execute_input":"2025-12-01T10:14:52.296392Z","iopub.status.idle":"2025-12-01T10:14:52.301656Z","shell.execute_reply.started":"2025-12-01T10:14:52.296363Z","shell.execute_reply":"2025-12-01T10:14:52.300613Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:15:35.471372Z","iopub.execute_input":"2025-12-01T10:15:35.471756Z","iopub.status.idle":"2025-12-01T10:15:35.478742Z","shell.execute_reply.started":"2025-12-01T10:15:35.471726Z","shell.execute_reply":"2025-12-01T10:15:35.477547Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:15:39.409288Z","iopub.execute_input":"2025-12-01T10:15:39.409591Z","iopub.status.idle":"2025-12-01T10:15:39.415419Z","shell.execute_reply.started":"2025-12-01T10:15:39.409548Z","shell.execute_reply":"2025-12-01T10:15:39.414230Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:16:34.097880Z","iopub.execute_input":"2025-12-01T10:16:34.098250Z","iopub.status.idle":"2025-12-01T10:16:34.105034Z","shell.execute_reply.started":"2025-12-01T10:16:34.098223Z","shell.execute_reply":"2025-12-01T10:16:34.103612Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:19:15.641850Z","iopub.execute_input":"2025-12-01T10:19:15.642248Z","iopub.status.idle":"2025-12-01T10:19:26.938352Z","shell.execute_reply.started":"2025-12-01T10:19:15.642214Z","shell.execute_reply":"2025-12-01T10:19:26.937464Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are set to revolutionize AI by providing enhanced processing power, faster AI model training, and the ability to solve complex problems currently beyond the reach of classical computers. These advancements include significant progress in qubit technology, improved error correction for greater reliability, and the development of hybrid quantum-classical systems.\n\nThe implications for AI are profound: we can expect AI systems that are more accurate, efficient, and capable of tackling major global challenges in areas like healthcare, climate change, and cybersecurity. While still in its developmental stages, the convergence of quantum computing and AI promises to redefine the future of computing and its impact across various industries.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:21:02.749066Z","iopub.execute_input":"2025-12-01T10:21:02.749429Z","iopub.status.idle":"2025-12-01T10:21:02.755294Z","shell.execute_reply.started":"2025-12-01T10:21:02.749403Z","shell.execute_reply":"2025-12-01T10:21:02.754346Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:21:05.264518Z","iopub.execute_input":"2025-12-01T10:21:05.264917Z","iopub.status.idle":"2025-12-01T10:21:05.271099Z","shell.execute_reply.started":"2025-12-01T10:21:05.264892Z","shell.execute_reply":"2025-12-01T10:21:05.269981Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:21:19.776935Z","iopub.execute_input":"2025-12-01T10:21:19.777617Z","iopub.status.idle":"2025-12-01T10:21:19.783095Z","shell.execute_reply.started":"2025-12-01T10:21:19.777589Z","shell.execute_reply":"2025-12-01T10:21:19.782089Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:21:21.523476Z","iopub.execute_input":"2025-12-01T10:21:21.523856Z","iopub.status.idle":"2025-12-01T10:21:21.530621Z","shell.execute_reply.started":"2025-12-01T10:21:21.523832Z","shell.execute_reply":"2025-12-01T10:21:21.529688Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:21:25.750214Z","iopub.execute_input":"2025-12-01T10:21:25.750524Z","iopub.status.idle":"2025-12-01T10:21:36.910902Z","shell.execute_reply.started":"2025-12-01T10:21:25.750502Z","shell.execute_reply":"2025-12-01T10:21:36.910014Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Outline:\n\n**Headline:** Supercharge Your Software: Unleash the Power of Multi-Agent Systems!\n\n**Introduction Hook:** Feeling overwhelmed by complex software challenges? Imagine a team of intelligent, specialized virtual assistants working tirelessly behind the scenes to build, test, and optimize your code. That's the transformative promise of Multi-Agent Systems (MAS) for software developers, and it's time you learned how they can revolutionize your workflow.\n\n---\n\n### 1. Enhanced Problem-Solving with Decentralized Intelligence\n\n*   **Breaking Down Complexity:** MAS allows for the decomposition of large, intricate problems into smaller, manageable sub-problems, each handled by an individual agent with specific expertise.\n*   **Resilience and Robustness:** If one agent fails or encounters an issue, the system can often continue functioning by redistributing tasks or relying on other agents, leading to more resilient software.\n*   **Parallel Processing Power:** Agents can operate concurrently, significantly speeding up development processes like testing, debugging, and even code generation through parallel execution.\n\n### 2. Streamlined Development Workflows and Automation\n\n*   **Automated Task Management:** Agents can be programmed to handle repetitive and time-consuming tasks, such as code refactoring, unit testing, dependency management, and deployment pipelines.\n*   **Intelligent Code Assistance:** Think AI-powered code completion, bug detection, and even suggestions for architectural improvements, all delivered by specialized agents.\n*   **Proactive Monitoring and Maintenance:** MAS can continuously monitor deployed applications, identify potential issues before they become critical, and even initiate self-healing mechanisms.\n\n### 3. Fostering Collaboration and Adaptability in Software Projects\n\n*   **Agent-to-Agent Communication:** MAS enables agents to communicate and coordinate their actions, mimicking human team collaboration to achieve complex goals more efficiently.\n*   **Dynamic System Adaptation:** Agents can learn from their environment and interactions, allowing the overall software system to adapt to changing requirements, user behavior, and external conditions.\n*   **Specialized Roles and Responsibilities:** Developers can assign specific roles and expertise to different agents, ensuring that each part of the development lifecycle is handled by the most suitable \"team member.\"\n\n---\n\n**Concluding Thought:** Multi-Agent Systems are no longer a futuristic concept; they are a powerful, practical tool available today. By embracing MAS, software developers can unlock new levels of efficiency, create more robust and adaptable applications, and ultimately spend more time on the creative and innovative aspects of software engineering. It's time to build smarter, not just harder.\nWriterAgent > ## Supercharge Your Software: Unleash the Power of Multi-Agent Systems!\n\nFeeling overwhelmed by complex software challenges? Imagine a team of intelligent, specialized virtual assistants working tirelessly behind the scenes to build, test, and optimize your code. That's the transformative promise of Multi-Agent Systems (MAS) for software developers, and it's time you learned how they can revolutionize your workflow.\n\nMAS breaks down daunting problems into smaller, manageable pieces, with each specialized agent tackling its unique expertise. This decentralized intelligence not only speeds up development through parallel processing but also builds resilience. If one agent falters, others can adapt, ensuring your project keeps moving forward.\n\nThe benefits extend to streamlining your entire workflow. MAS agents can automate mundane tasks like code refactoring, unit testing, and deployment, freeing you from repetitive work. Think of AI-powered code completion, proactive bug detection, and even intelligent suggestions for architectural improvements. Beyond development, these agents can continuously monitor deployed applications, identifying and even resolving issues before they impact users.\n\nFurthermore, MAS fosters a dynamic and collaborative development environment. Agents communicate and coordinate, much like a human team, to achieve intricate goals. This allows your software systems to dynamically adapt to changing requirements and user behaviors. By assigning specialized roles to each agent, you ensure every aspect of your project is handled by the most capable \"team member.\"\n\nMulti-Agent Systems are here, offering a practical path to increased efficiency, enhanced robustness, and greater adaptability. Embrace MAS, and spend more time innovating, less time struggling. It's time to build smarter.\nEditorAgent > ## Supercharge Your Software: Unleash the Power of Multi-Agent Systems!\n\nAre you grappling with complex software challenges? Picture this: a team of intelligent, specialized virtual assistants working diligently behind the scenes to build, test, and optimize your code. This is the revolutionary potential of Multi-Agent Systems (MAS) for software developers, and it's time you discovered how they can transform your workflow.\n\nMAS tackles daunting problems by breaking them into smaller, more manageable components, with each specialized agent leveraging its unique expertise. This decentralized intelligence not only accelerates development through parallel processing but also enhances resilience. Should one agent encounter an issue, others can adapt, ensuring your project progresses without interruption.\n\nThe advantages permeate your entire workflow. MAS agents can automate routine tasks like code refactoring, unit testing, and deployment, liberating you from repetitive work. Imagine AI-powered code completion, proactive bug detection, and even intelligent suggestions for architectural enhancements. Beyond the development phase, these agents can continuously monitor deployed applications, identifying and resolving issues before they impact users.\n\nMoreover, MAS cultivates a dynamic and collaborative development environment. Agents communicate and coordinate their actions, much like a human team, to achieve intricate objectives. This empowers your software systems to adapt dynamically to evolving requirements and user behaviors. By assigning specialized roles to each agent, you guarantee that every facet of your project is handled by the most proficient \"team member.\"\n\nMulti-Agent Systems are a reality today, offering a practical route to heightened efficiency, improved robustness, and greater adaptability. Embrace MAS, and dedicate more time to innovation while reducing time spent on challenges. It's time to build smarter.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:27:11.110156Z","iopub.execute_input":"2025-12-01T10:27:11.110538Z","iopub.status.idle":"2025-12-01T10:27:11.116963Z","shell.execute_reply.started":"2025-12-01T10:27:11.110512Z","shell.execute_reply":"2025-12-01T10:27:11.115941Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:27:16.930518Z","iopub.execute_input":"2025-12-01T10:27:16.930881Z","iopub.status.idle":"2025-12-01T10:27:16.937292Z","shell.execute_reply.started":"2025-12-01T10:27:16.930857Z","shell.execute_reply":"2025-12-01T10:27:16.936370Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:27:22.431447Z","iopub.execute_input":"2025-12-01T10:27:22.432870Z","iopub.status.idle":"2025-12-01T10:27:22.439886Z","shell.execute_reply.started":"2025-12-01T10:27:22.432836Z","shell.execute_reply":"2025-12-01T10:27:22.438534Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:27:40.770600Z","iopub.execute_input":"2025-12-01T10:27:40.770948Z","iopub.status.idle":"2025-12-01T10:27:40.778014Z","shell.execute_reply.started":"2025-12-01T10:27:40.770913Z","shell.execute_reply":"2025-12-01T10:27:40.776985Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:28:05.875364Z","iopub.execute_input":"2025-12-01T10:28:05.875751Z","iopub.status.idle":"2025-12-01T10:28:05.881893Z","shell.execute_reply.started":"2025-12-01T10:28:05.875723Z","shell.execute_reply":"2025-12-01T10:28:05.880791Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:28:09.318401Z","iopub.execute_input":"2025-12-01T10:28:09.319273Z","iopub.status.idle":"2025-12-01T10:28:23.629992Z","shell.execute_reply.started":"2025-12-01T10:28:09.319240Z","shell.execute_reply":"2025-12-01T10:28:23.629010Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > Here are three key AI/ML trends, the companies involved, and their potential impact:\n\n**1. Generative AI for Complex Content Creation:** This trend sees AI models creating diverse content beyond text, including graphics, video, and music. Major players like Google (with models like Imagen and Muse) and OpenAI are at the forefront. The impact includes enhanced artistic expression and new practical applications across industries.\n\n**2. Agentic AI:** AI agents are autonomous software entities capable of gathering data, planning, and acting with high autonomy. Tech giants like Google and Microsoft are investing heavily in this area. This trend promises faster, more accurate business decisions, reduced manual errors, and unprecedented optimization scales.\n\n**3. Multimodal AI:** This involves AI systems that can process and understand multiple types of data simultaneously, like images, video, and voice. Companies such as Google and Amazon are developing these capabilities. The impact is more natural and efficient human-AI interactions, improving user experience and driving broader AI adoption.\n\nThese advancements, spearheaded by companies like Google, Microsoft, and Amazon, are poised to revolutionize various sectors by enhancing creativity, automating complex tasks, and enabling more intuitive human-computer interfaces.\nHealthResearcher > Here's a briefing on recent breakthroughs in Tech, Health, and Finance:\n\n**Health:**\n*   **AI-Powered Diagnostics:** AI is revolutionizing early disease detection, with tools now identifying lung cancer more accurately than radiologists and even predicting diseases years before symptoms appear. By 2026, AI agents will manage patient journeys and assist in research.\n*   **CRISPR Gene Editing:** The first CRISPR-based therapy, Casgevy, was approved in 2023 for inherited blood disorders, marking a significant step for gene editing treatments. Advancements in CRISPR combined with AI show promise for genetic therapies by 2026.\n*   **Regenerative Medicine:** Innovative methods are emerging for tissue regeneration, aiming to minimize rejection risks. Expect advancements in muscle tissue regeneration and broader applications for personalized medicine.\n\n**Technology:**\n*   **Generative AI in Drug Discovery:** Generative AI is accelerating the identification and testing of new drug candidates, with significant breakthroughs expected to enter clinical trials by 2025-2026, potentially leading to more affordable cures.\n*   **AI Agents:** Building on current AI chatbots, AI agents will be capable of taking action and performing complex tasks. In healthcare, these could manage patient care from triage to follow-up.\n*   **Virtual Hospitals:** Telemedicine is evolving into virtual hospitals, offering comprehensive care remotely, connecting facilities globally, and expanding access to specialists.\n\n**Finance:**\n*   **AI and Machine Learning in Finance:** AI is increasingly used for hyper-personalization, trend prediction, and enhancing back-office operations. By 2026, AI-driven autonomous finance platforms will democratize professional-grade financial management.\n*   **Tokenization:** This blockchain-based technology, enabling asset ownership transfer without intermediaries, is a long-term trend to watch. Stablecoins, a form of tokenized US dollars, saw transaction volumes surpass Visa and Mastercard combined in 2024.\n*   **Embedded Finance:** Financial services are being integrated into non-financial platforms, making them more accessible and seamless for consumers. This trend is expected to become a must-have for customer engagement.\nFinanceResearcher > # Daily Executive Briefing\n\n## Fintech Trends:\n\n**1. AI and ML Integration:** Artificial Intelligence (AI) and Machine Learning (ML) are increasingly vital in fintech for fraud detection, personalized services, and operational efficiency. The AI in fintech market is projected to grow significantly, becoming a key differentiator.\n\n**Market Implications:** This trend enhances security, improves customer experience through personalization, and streamlines internal processes, potentially leading to increased profitability for early adopters.\n\n**Future Outlook:** AI and ML will become foundational, driving innovation in areas like generative AI for financial services, predictive analytics, and personalized financial advice.\n\n**2. Evolving Payment Technologies and Open Banking:** Emerging payment technologies, including digital wallets and real-time/instant payments, are gaining mainstream adoption. Open Banking, and its extension to Open Finance, continues to expand, facilitating secure data sharing and efficient payment processes.\n\n**Market Implications:** Increased competition and innovation in payment solutions, with potential benefits for consumers through greater choice and convenience, but also risks related to data security.\n\n**Future Outlook:** Payments will become more seamless and integrated into non-financial platforms (embedded finance), while Open Banking/Finance will drive greater data interoperability and customer empowerment.\n\n**3. Regulatory Scrutiny and Cybersecurity:** As fintech matures, regulatory oversight is intensifying globally. Concurrently, the rise in digital transactions elevates the importance of robust cybersecurity measures and fraud prevention.\n\n**Market Implications:** Fintech companies must navigate complex and evolving regulatory landscapes, investing heavily in compliance and cybersecurity to build trust and avoid penalties.\n\n**Future Outlook:** A more regulated and secure fintech environment, where compliance and data protection are paramount, potentially leading to a more stable and trustworthy sector.\n\n---\n\n## Technology Trends:\n\n**1. AI Everywhere and Agentic AI:** Artificial Intelligence continues its pervasive growth, with a focus shifting towards \"agentic AI\" capable of autonomous planning and execution. This trend spans across various sectors, driving innovation and efficiency.\n\n**Market Implications:** Businesses that leverage AI, especially agentic AI, can gain significant competitive advantages through automated workflows, predictive capabilities, and real-time adaptation.\n\n**Future Outlook:** AI will become deeply embedded in business operations, evolving from analytical tools to proactive, autonomous agents.\n\n**2. Cloud, Edge, and Connectivity (5G/IoT):** The expansion of cloud computing, coupled with the growth of edge computing and enhanced connectivity through 5G networks, is transforming infrastructure. This enables more distributed data processing and real-time applications.\n\n**Market Implications:** Enhanced operational efficiency, lower latency for applications, and the proliferation of Internet of Things (IoT) devices, driving innovation in areas like smart infrastructure and remote operations.\n\n**Future Outlook:** A more decentralized and connected digital infrastructure, supporting sophisticated real-time data processing and advanced applications.\n\n**3. Quantum Computing and Specialized Chips:** Advancements in quantum computing and specialized semiconductor chips are poised to unlock unprecedented processing power. This will impact fields from scientific research to complex data analysis.\n\n**Market Implications:** Potential for breakthroughs in scientific discovery, drug development, and complex problem-solving. It also presents challenges related to encryption and security.\n\n**Future Outlook:** Quantum computing will transition from a theoretical concept to a practical tool for specific, high-demand computational tasks, reshaping industries reliant on intensive data processing.\n\n---\n\n## Health Trends:\n\n**1. AI in Diagnostics and Personalized Medicine:** AI is revolutionizing healthcare by enabling more accurate diagnostics, personalized treatment plans, and predictive analytics for patient outcomes.\n\n**Market Implications:** Improved patient care, potentially lower long-term costs through early intervention, and a shift towards more proactive and individualized health management.\n\n**Future Outlook:** AI will be integral to healthcare delivery, driving precision medicine, enhancing clinical decision-making, and improving overall patient advocacy.\n\n**2. Shift to Home-Based and Value-Based Care:** There's a significant acceleration towards care delivery in lower-acuity settings, including home and virtual services, aligning with patient preferences for convenience and cost-effectiveness. This is driven by value-based care models that focus on outcomes and efficiency.\n\n**Market Implications:** Redefined care delivery models, increased patient empowerment, and a greater emphasis on preventative care. Organizations must adapt their strategies to accommodate this shift, impacting facility utilization and service provision.\n\n**Future Outlook:** A more patient-centric healthcare system where care is increasingly delivered outside traditional hospital settings, with a strong emphasis on outcomes and cost-efficiency.\n\n**3. Addressing Workforce Shortages and Rising Costs:** The healthcare industry continues to grapple with workforce shortages and escalating costs. Technology, including AI and automation, is seen as a key enabler to streamline workflows, reduce administrative burdens, and mitigate these challenges.\n\n**Market Implications:** Increased adoption of technology to optimize operations and support healthcare professionals, aiming to improve efficiency and sustainability amidst persistent cost pressures and labor gaps.\n\n**Future Outlook:** Technology will play a crucial role in augmenting the healthcare workforce, improving operational resilience, and managing financial pressures, ensuring continued access to care.\nAggregatorAgent > ## Executive Summary: Convergence of AI, Health, and Finance Innovations\n\nThe latest breakthroughs across technology, health, and finance reveal a powerful convergence, primarily driven by advancements in Artificial Intelligence. **Agentic AI**, capable of autonomous planning and action, is a central theme, promising to revolutionize decision-making in business, patient care management, and financial services by 2026. This trend, alongside **Generative AI** for content creation and **Multimodal AI** for richer interactions, is poised to enhance creativity and efficiency across all sectors.\n\nIn healthcare, AI is transforming diagnostics for earlier and more accurate disease detection, while **Generative AI** is accelerating drug discovery, with potential breakthroughs entering clinical trials soon. **AI agents** are expected to manage patient journeys, and virtual hospitals are expanding access to care. Similarly, finance is leveraging AI for hyper-personalization, fraud detection, and autonomous financial platforms.\n\nSurprising connections emerge in the application of AI to solve complex problems. From creating novel drugs to enabling personalized treatments and optimizing financial management, AI's impact is profound and increasingly integrated. Key takeaways include the imminent shift towards highly autonomous AI systems, the critical role of AI in driving personalized solutions, and the growing importance of seamless digital integration, from embedded finance to virtual healthcare. Companies must prioritize AI adoption to remain competitive and innovative.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:44:21.161262Z","iopub.execute_input":"2025-12-01T10:44:21.161693Z","iopub.status.idle":"2025-12-01T10:44:21.168704Z","shell.execute_reply.started":"2025-12-01T10:44:21.161655Z","shell.execute_reply":"2025-12-01T10:44:21.167651Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:44:41.373712Z","iopub.execute_input":"2025-12-01T10:44:41.374093Z","iopub.status.idle":"2025-12-01T10:44:41.380816Z","shell.execute_reply.started":"2025-12-01T10:44:41.374068Z","shell.execute_reply":"2025-12-01T10:44:41.379486Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:45:02.144399Z","iopub.execute_input":"2025-12-01T10:45:02.144897Z","iopub.status.idle":"2025-12-01T10:45:02.150830Z","shell.execute_reply.started":"2025-12-01T10:45:02.144867Z","shell.execute_reply":"2025-12-01T10:45:02.149511Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:45:22.460743Z","iopub.execute_input":"2025-12-01T10:45:22.461080Z","iopub.status.idle":"2025-12-01T10:45:22.468343Z","shell.execute_reply.started":"2025-12-01T10:45:22.461054Z","shell.execute_reply":"2025-12-01T10:45:22.467287Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:45:35.664463Z","iopub.execute_input":"2025-12-01T10:45:35.664795Z","iopub.status.idle":"2025-12-01T10:45:35.670805Z","shell.execute_reply.started":"2025-12-01T10:45:35.664773Z","shell.execute_reply":"2025-12-01T10:45:35.669540Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T10:45:50.700518Z","iopub.execute_input":"2025-12-01T10:45:50.700863Z","iopub.status.idle":"2025-12-01T10:46:03.814742Z","shell.execute_reply.started":"2025-12-01T10:45:50.700839Z","shell.execute_reply":"2025-12-01T10:46:03.813721Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias traced the salt-crusted rim of his mug, the lighthouse beam sweeping its steady rhythm across the churning sea. Another night, much like any other. Then, a glint from the dusty floorboards near the old sea chest. He knelt, his fingers brushing against something smooth and cool. It was a rolled parchment, tied with a thread that hummed with faint light. Unfurling it, Elias gasped. Not paper, but some unknown, leathery material, it displayed a map, shimmering with an inner luminescence. Strange symbols pulsed, detailing a coastline he‚Äôd never seen, and a single, burning X marked a point far beyond known shipping lanes. The beam swung, and for a moment, the map seemed to reflect its light, the X glowing brighter. Elias felt a thrill, a dangerous, exhilarating spark, ignite within him.\nCriticAgent > The story sets up an intriguing mystery with the discovery of the glowing map. The character of Elias is established as a solitary lighthouse keeper, which fits the mood. The pacing is good, moving from the mundane to the extraordinary swiftly.\n\nHere are a couple of suggestions for improvement:\n\n1.  **Flesh out Elias's reaction to the map:** While Elias feels a \"thrill,\" delve a bit deeper into his thoughts and emotions. Is he purely excited, or is there a hint of fear, skepticism, or even dread given the map's unusual nature and its unknown destination? Showing more of his internal conflict or contemplation would add depth.\n2.  **Hint at the map's potential origin or purpose:** The map is described as being on an \"unknown, leathery material\" with \"strange symbols.\" While keeping it mysterious is good, a subtle hint could enhance the intrigue. For example, perhaps the thread humming with light has a specific, almost familiar texture, or the symbols bear a faint resemblance to something Elias has seen or heard of in obscure maritime lore. This would give the reader something more to ponder about the map's origins without giving away too much.\nRefinerAgent > Elias traced the salt-crusted rim of his mug, the lighthouse beam sweeping its steady rhythm across the churning sea. Another night, much like any other, the endless cycle of light and dark, the gnawing solitude his only companion. Then, a glint from the dusty floorboards near the old sea chest, a flicker that snagged his attention. He knelt, his fingers brushing against something smooth and cool, alien to the rough-hewn wood. It was a rolled parchment, tied with a thread that hummed with faint, otherworldly light, a light that seemed to pulse in time with his own quickening heartbeat. Unfurling it, Elias gasped. Not paper, but some unknown, leathery material, supple yet resilient, it displayed a map, shimmering with an inner luminescence. Strange symbols, like no script he‚Äôd ever encountered, pulsed with an inner fire, detailing a coastline he‚Äôd never seen, and a single, burning X marked a point far beyond known shipping lanes. The beam swung, and for a moment, the map seemed to absorb and then reflect its light, the X flaring with an impossible intensity. A thrill shot through Elias, sharp and exhilarating, quickly followed by a cold tendril of fear. This was no ordinary chart; it whispered of forgotten depths, of places men were not meant to find. Skepticism warred with a burgeoning sense of destiny. The thread, he noticed, felt strangely familiar, like scales shed from some ancient leviathan, a texture whispered about in hushed tones by old sailors recounting impossible tales. Could this be from one of those forgotten voyages, a remnant of a world lost to the waves and time? The map pulsed again, the X a siren‚Äôs call, and Elias felt a dangerous, exhilarating spark ignite within him, a profound pull towards the unknown, a longing he hadn't realized lay dormant in his solitary heart.\nCriticAgent > The story successfully establishes a strong atmosphere and introduces a compelling mystery. Elias's character, though simple, serves well as the focal point for the unfolding events. The pacing is effective in building intrigue and capturing Elias's discovery.\n\nHere are a few suggestions for improvement:\n\n1.  **Enhance the sensory details of the map:** While the luminescence and pulsing are good, consider adding other sensory details. What does the \"unknown, leathery material\" *smell* like? Does it have a unique texture beyond being \"smooth and cool\"? Does it make a sound when unfurled or pulsed? Adding more specific, tangible details can make the map feel even more real and otherworldly.\n2.  **Show, don't just tell, Elias's inner conflict:** Phrases like \"Skepticism warred with a burgeoning sense of destiny\" are good indicators, but showing Elias physically reacting to this internal struggle would be more impactful. For example, does he clench his jaw, his hand tremble as he reaches for the map, or does he look around the familiar lighthouse as if seeking reassurance before committing to this unknown path?\n3.  **Connect the \"faint, otherworldly light\" of the thread more directly to the map's symbols or luminescence:** The thread is described as humming with light that pulses with Elias's heartbeat. Later, the symbols on the map pulse with \"inner fire\" and the X flares with \"impossible intensity.\" A stronger connection or a mirroring of these light qualities between the thread and the map's markings could create a more cohesive magical element.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}